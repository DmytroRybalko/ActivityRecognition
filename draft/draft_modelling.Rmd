---
title: "Draft Modelling"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)

library(tidyverse)
library(caTools)
library(ROCR)
library(rpart)
library(rpart.plot)
library(randomForest)
library(caret)
library(e1071)
```

# Agenda:

1) Type of datesets: raw, normalized, partial normalized  
2) PCA exploring, correlation finding, reduction dimension  
3) Cross-validation  
4) Classification algorithms:  
4.1) decision tree DS;  
4.2) random forest;  
4.3) k-NN;  

# 1.Data preparing

## Load features:

```{r}
raw_features <- readRDS("data/preprocessing/features_v1.rds")
norm_features <- readRDS("data/preprocessing/norm_features_v1.rds")
```

Data looks like:
```{r}
raw_features
```

Convert user_id value to factor:
```{r}
raw_features <- raw_features %>% 
  mutate_at("user_id", ~factor(., levels = as.character(1:10)))
str(raw_features)
```


## 1.2 Split data into a training and test sets

### Var1
```{r}
# set.seed(3000)
# spl <- sample.split(raw_features$user_id, SplitRatio = 0.7)
```
Now, let's create our training and testing sets using the subset function.
```{r}
# train.data <- subset(raw_features, spl == TRUE)
# test.data <- subset(raw_features, spl == FALSE)
```

### Var2

Now, let's create our training and testing sets using the subset function.
```{r}
spl <- createDataPartition(raw_features$user_id, p = 0.7, list = F)
train.data <- raw_features[spl,]
test.data <- raw_features[-spl,]
```

## 3.Cross-validation   

### rpart
First, we need to define how many folds we want. We can do this using the trainControl function.  
```{r}
numFolds <- trainControl(method = "cv", number = 10)
```
  
Then we need to pick the possible values for our cp parameter, using the expand.grid function. So we'll call it cpGrid, and then use expand.grid, where the only argument is .cp = seq(0.01,0.5,0.01). This will define our cp parameters to test as numbers from 0.01 to 0.5, in increments of 0.01.
```{r}
# tuneGrid parameters for rpart
cpGrid <- expand.grid(.cp = seq(0.01, 0.5, 0.01))
```

Now, we're ready to perform cross validation. 
```{r, cache=TRUE, eval=FALSE}
train(user_id ~ ., data = train.data, method = "knn", trControl = numFolds, tuneGrid = tune.knn)
```
The final value used for the model was cp = 0.1. This is the cp value we want to use in our CART model.  

So now let's create a new CART model with this value of cp, instead of the minbucket parameter.

# 4.Classification algorithms

## 4.1. Decision Tree (DS)

### 4.1.1 Create the model with train data!

```{r}
base.CART <- rpart(user_id ~ ., data = train.data, method = "class", cp = 0.1)
```
Now let's plot our tree using the prp function
```{r}
prp(base.CART)
```

### 4.2.1 Make prediction on train data

Now let's see how well our CART model does at making predictions for the **train** set.
```{r}
predict.CART.train <- predict(base.CART, newdata = train.data, type = "class") #train.data[,-1]
```

Now let's compute the accuracy of our model by building a confusion matrix.
```{r}
confusionMatrix(reference = train.data$user_id, data = predict.CART.train,         
                mode = "prec_recall", dnn = c("Reference", "Prediction"))
```

### 4.1.2 Make prediction on test data

Now let's see how well our CART model does at making predictions for the **test** set.
```{r}
predict.CART.test <- predict(base.CART, newdata = test.data, type = "class")
```
Now let's compute the accuracy of our model by building a confusion matrix.
```{r}
confusionMatrix(reference = test.data$user_id, data = predict.CART.test,         
                mode = "prec_recall")
```
Try to make zeros at upper diagonale:
```{r}
confusionMatrix(reference = test.data$user_id, data = predict.CART.test,         
                mode = "prec_recall",
                prevalence = c("1" = 0.07, "2" = 0.07, "3" = 0, "4" = 0, "5" = 0,
                               "6" = 0, "7" = 0, "8" = 0, "9" = 0, "10" = 0))
```


### Use table() function

Make prediction
```{r}
#predict.CART.prob <- predict(base.CART, newdata = test.data, type = "prob")
```

Predict
```{r}
predict.CART <- as_tibble(predict(base.CART, newdata = test.data, type = "p"))
#head(predict.CART)
```

Confusion matrix
table(iris$Y, pdata$`1` > .5)

```{r}
table(test.data$user_id, predict.CART$`1` > 0.3)
```


## 4.2 Randome Forest

Build the model
```{r}
random.forest <- randomForest(user_id ~ ., data = train.data, nodesize = 25, ntree = 200, importance = T)
```

Make prediction
```{r}
predict.RF.test <- predict(random.forest, newdata = test.data)
```

See result
```{r}
confusionMatrix(reference = test.data$user_id, data = predict.RF.test,         
                mode = "prec_recall", dnn = c("Reference", "Prediction"))
```
Plot randm forest:
```{r}
plot(random.forest)
```
Random Forest importance parameter:
```{r}
#nn <- rownames(random.forest$importance)
MeanDecreaseGini <- random.forest$importance %>%
  as_tibble(rownames = "features") %>% 
  select(features, MeanDecreaseAccuracy, MeanDecreaseGini) %>% 
  arrange(desc(MeanDecreaseGini))
MeanDecreaseGini
```

```{r}
 
varImpPlot(rf.fit, n.var=35, main = "Variable Importance Plot", pch=16, scale = F)
```

# TODO Build bar chart!

## 3. k-NN

```{r}
knn.fit <- train(user_id ~ ., data = train.data, method = "knn", preProcess = c("center", "scale"), tuneLength = 10, trControl = trainControl(method = "cv"))
```

Look inside
```{r}
knn.fit
```

Make prediction
```{r}
predict.knn <- predict(knn.fit, newdata = test.data)
```

See result (виправлена!)
```{r}
confusionMatrix(reference = test.data$user_id, data = predict.knn,         
                mode = "prec_recall")
```
# !!! ВИПРАВИТИ МАТРИЦЮ!!!
```{r}
confusionMatrix(data = test.data$user_id, reference = predict.knn,         
                mode = "prec_recall", dnn = c("Reference", "Prediction"))
```


### 3.1 pure k-NN

Build model
```{r}
knn3.fit <- knn3(user_id ~ ., train.data , k = 5)
```

Make prediction:
```{r}
predict.knn3 <- predict(knn3.fit, newdata = test.data)
```

Confusion matrix:
```{r}
confusionMatrix(reference = test.data$user_id, data = predict.knn3,         
                mode = "prec_recall", dnn = c("Reference", "Prediction"))
```

### 4 Logistic regression

#### regLogistic	

Build model
```{r}
logreg.fit <- train(user_id ~ ., data = train.data, method = "regLogistic", trControl = trainControl(method = "cv"))
```

Make prediction:
```{r}
predict.knn3 <- predict(knn3.fit, newdata = test.data)
```

Confusion matrix:
```{r}
confusionMatrix(reference = test.data$user_id, data = predict.knn3,         
                mode = "prec_recall", dnn = c("Reference", "Prediction"))
```

#### base R
```{r}
logreg <- glm(user_id ~ ., data = train.data, family = binomial)
```

Now, let's look at our model using the summary function.
```{r}
summary(logreg)
```

Make prediction
```{r}
predict.logreg <- predict(logreg, newdata = test.data, type = "response")
```

See result:
```{r}
table(test.data$user_id, predict.logreg >= 0.7)
```


## Next steps:
use knn without train
use logreg
how to increase recall?

