---
title: "Untitled"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
```

# Project describe

Задача: обучившись на одном человеке, модель должна уметь отличить его от других. То есть когда подаём на вход его записи - выдаё 1, во всех остальных случаях - 0
  
[Activity Recognition from Single Chest-Mounted Accelerometer Data Set](https://archive.ics.uci.edu/ml/datasets/Activity+Recognition+from+Single+Chest-Mounted+Accelerometer)
  

## Dataset Information
   --- Data are separated by participant
   --- Each file contains the following information
       ---- sequential number, x acceleration, y acceleration, z acceleration, label 
   --- Labels are codified by numbers
       --- 1: Working at Computer
       --- 2: Standing Up, Walking and Going up-down stairs
       --- 3: Standing
       --- 4: Walking
       --- 5: Going Up-Down Stairs
       --- 6: Walking and Talking with Someone
       --- 7: Talking while Standing  
  
## Useful paper

### 1) Activity Recognition from Accelerometer Data.pdf  
  
### 2) [Person Recognition using Smartphones’ Accelerometer Data](https://arxiv.org/pdf/1711.04689.pdf)  
  
  
### 3) [Machine Learning Methods for Classifying Human Physical Activity from On-Body Accelerometers](https://www.mdpi.com/1424-8220/10/2/1154/htm)  
> Our results agree with the findings by [32], in spite of a slightly different approach to classifier construction. While they train each classifier by using examples from all tested subjects, we prefer to train separately one classifier for each subject, averaging the individual classification accuracies to yield the results shown in Tables 5, 6, and 7. We believe that a subject-specific training is important especially for the cHHM-based sequential classifier, because of the high mannerism exhibited by humans while performing a given physical activity.  

## Workflow
    
...The input of our experiment is n positive points from the legitimate user and n negative data points from randomly selected n other users (Multi-sensor authentication to improve smartphone security)  
  
## Approaches to comparison time series
cross-correlation
frequency coherence,
dynamic time warping
autocorrelation  

## Features  
 
**Motion**  
+ Walking speed (m/s) or RMS of the Integral (RMS Velocity)  
+ Cadence (steps/min)  
  
**Statistic**  
Mean
Standard deviation
Correlation  
Median frequency
Mode frequency corresponding to the dominant frequency
First quartile
Third quartile
Interquartile range
Centroid
Kurtosis
Skewness
  
**Geometry**  
+ Number of Zero crossings (after centering)  (sueur_j_sound_analysis_and_synthesis_with_r, p.421, 423)
+ Peak-to-peak value  


**Signal Entropy** (sueur_j_sound_analysis_and_synthesis_with_r, p.299)  
+ spectral flatness measure  
+ spectral evenness  
+ frequency precision or resolution of the spectrum  
  
**Unclassified yet)**  
+ Energy(?) - (sueur_j_sound_analysis_and_synthesis_with_r, p.427)
+ frequency-domain entropy  
+ Crest Factor  
+ dominant frequency - the frequency of highest energy  
+ fundamental frequency  
+ formants frequency  
+ instantaneous frequency  ()
  
В якості фіч для розпізнання активностей між собою спробувати використати навігаційні параметри: швидкість (модуль швидкості), вектор сили тяжіння. Це можна використати для розрізнення режиму ходіння та підйому по сходах.

